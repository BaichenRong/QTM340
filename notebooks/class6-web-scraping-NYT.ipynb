{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping on the Actual Web\n",
    "\n",
    "The [class 5 notebook](class5-web-scraping-preview.ipynb) explained all of the steps involved in web scraping. But what about when it comes time to try it on the actual web? \n",
    "\n",
    "We're going to use this [*The New York Times* article](https://www.nytimes.com/interactive/2019/08/19/us/politics/presidential-campaign-songs-playlists.html) about 2020 presidental candidate playlists as our real-world example. Our task for today's class is to scrape it for a list of all the songs that the candidates have played."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Does anyone rememeber the first step?**\n",
    "\n",
    "Hint: It involves the Requests library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the requests library and request the contents of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've gotten the contents of the page, it's a good idea to take a look. \n",
    "\n",
    "**How can you print the response from the server as text?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, see what it looks like\n",
    "html_str = # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa! That's a lot more complicated than kittens! Let's go back to Chrome and take a look using View Source.\n",
    "\n",
    "To get a lay of the (HTML) land, try doing a simple command-f for \"Aretha\" (as in Franklin; the first artist mentioned at the top of the site). \n",
    "\n",
    "**First round of questions for the class**:\n",
    "* **What is the tag enclosing the first mention of Aretha Franklin?** \n",
    "* **Does this tag have an attribute, and if so, what it is?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a little review and see if we can remember how to find all tags with specific attribute.\n",
    "\n",
    "* **What is the BeautifulSoup function we should use?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's review the syntax of find_all when you want to include an attribute as a parameter. It looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to import BeautifulSoup since we haven't yet used it in this notebook\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# now let's use BeautifulSoup to parse the html document that we got from the web just a few minutes ago\n",
    "document = BeautifulSoup(html_str, \"html.parser\")\n",
    "\n",
    "# and now let's do our find_all query for <span> tags with the value \"class\" and attribute \"song-artist\"\n",
    "document.find_all(\"span\", attrs={\"class\": \"song-artist\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! We're getting somewhere! But first, one last thing to learn about BeautifulSoup that we didn't have time to cover yesterday: traversing the HTML document tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A final helpful method for finding sibling tags\n",
    "\n",
    "Sometimes, the tags we're looking for don't have a distinguishing characteristic, like a `class` attribute with a specific value that allows us to find them using `.find()` and `.find_all()`. Other times (or sometimes in addition), and the tags also aren't in a nice neat parent-child structure that we can traverse easily. This can be tricky! Take the following HTML snippet, for example:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "<h2>Camembert</h2>\n",
    "<p>A soft cheese made in the Camembert region of France.</p>\n",
    "\n",
    "<h2>Cheddar</h2>\n",
    "<p>A yellow cheese made in the Cheddar region of... France, probably, idk whatevs.</p>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our task was to print the name of the cheese followed by the description that follows in the `<p>` tag directly afterward, we'd be out of luck. \n",
    "\n",
    "Fortunately, Beautiful Soup has a `.find_next_sibling()` method, which allows us to search for the next tag that is the *next sibling* of the tag you're calling it on (i.e., the two tags share a parent), that also matches particular criteria. \n",
    "\n",
    "So, for example, to accomplish the task outlined above, we'd do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert that html up above into a string that we can use\n",
    "# and remember, from the homework, the triple-quote synatax for feeding in more than a single line of text\n",
    "\n",
    "cheese_html = \"\"\" \n",
    "<h2>Camembert</h2>\n",
    "<p>A soft cheese made in the Camembert region of France.</p>\n",
    "\n",
    "<h2>Cheddar</h2>\n",
    "<p>A yellow cheese made in the Cheddar region of... France, probably, idk whatevs.</p>\n",
    "\"\"\"\n",
    "\n",
    "# now parse our cheese_html web doc using BeautifulSoup \n",
    "cheese_doc = BeautifulSoup(cheese_html, \"html.parser\")\n",
    "\n",
    "# define a dictionary for future use \n",
    "# and remember, a dictionary is a data structure like a list but key/value pairs\n",
    "cheese_dict = {}\n",
    "\n",
    "# first find all the h2 tags\n",
    "for h2_tag in cheese_doc.find_all('h2'):\n",
    "    # the cheese name is easy: that's the text in the h2 tag, so just use the .string attribute\n",
    "    cheese_name = h2_tag.string\n",
    "    \n",
    "    # but then we need to find the description\n",
    "    # here's where we use \"find_next_sibling\":\n",
    "    cheese_desc_tag = h2_tag.find_next_sibling('p')\n",
    "    \n",
    "    # now, we could just print the string version of cheese_desc_tag and be done\n",
    "    # but we're practicing dictionaries right now too, so we'll associate the key with the value like this:\n",
    "    cheese_dict[cheese_name] = cheese_desc_tag.string\n",
    "\n",
    "# when we're done, dump out our dictionary\n",
    "cheese_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, armed with our three BeautifulSoup methods, `find()`, `find_all()`, and `find_next_sibling()`, we've got everything we need to move on with our NYT web-scraping project. \n",
    "\n",
    "Let's go back to the HTML of our *New York Times* feature that we're scraping. \n",
    "\n",
    "Remember--in Chrome, you can use either `View->Developer->View source` if it doesn't seem that complicated--or, like this particular page, if it's well-formatted. But you can also use `View->Developer->Developer Tools` if you're not entirely sure what you're looking for, or if you like that nesting feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go look at it in view source..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are always multiple ways to scrape text from a web page, but since we've just learned the `find_next_sibling` method, let's try to incorporate that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember, we already have our \"document\" object from up above, which is the whole doc parsed by Beautiful Soup\n",
    "\n",
    "# so we can jump into...\n",
    "title_tags = document.find_all('song-title')\n",
    "\n",
    "title_tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But this does not work... why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try again with the *attribute* value as \"song-title\" rather than the tag itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags = document.find_all(\"span\", attrs={\"class\": \"song-title\"})\n",
    "\n",
    "title_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's format the song titles nicely into a list. \n",
    "\n",
    "NB: I'm doing this both so you remember the `.string` attribute and also to make sure I tell you about the `append()` method for adding values to lists, which I forgot to tell you about last class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_titles = [] # define a list for future use\n",
    "\n",
    "for title in title_tags:\n",
    "    song_titles.append(title.string) # the append method is how you add elements to the end of the list\n",
    "                                     # and remember the convenient .string attribute!  \n",
    "    \n",
    "song_titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we've got more work to do:\n",
    "\n",
    "Since the ultimate goal is to have the song title and artist name associated with each other, we're going to have to put a few things that we've recently learned all together.  \n",
    "\n",
    "To begin, let's take another look at this HTML:\n",
    "\n",
    "```\n",
    "<div class=\"song order-1\">\n",
    "    <span class=\"song-title\">Respect</span>`\n",
    "    <span class=\"song-artist\">Aretha Franklin</span>`\n",
    "</div>```\n",
    "\n",
    "**What is the relationship between the tag with the song title and the tag with the song artist?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And what Beautiful Soup method lets us find siblings?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can get started. \n",
    "\n",
    "Since we're looking to associate each song's title with the song's artist, this is a perfect use case for a dictionary. \n",
    "\n",
    "But note, since some artists have multiple songs, and dictionaries can't have multiple keys that are the same, we're going to make our dictionary in the format title/artist rather than the other way around. \n",
    "\n",
    "In any case, let's start with that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dict\n",
    "song_dict = {}  # goal is format {song title, artist}\n",
    "\n",
    "# then what? \n",
    "\n",
    "# 1) find all title tags\n",
    "## your code here\n",
    "\n",
    "\n",
    "# 2) then find the sibling of each of the title tags\n",
    "\n",
    "\n",
    "    # and add it to the dict (and be sure to add only the string)\n",
    "    \n",
    "    \n",
    "song_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Amazing! We did it!**\n",
    "\n",
    "And one final note:\n",
    "\n",
    "### When things go wrong with Beautiful Soup\n",
    "\n",
    "A number of things might go wrong with Beautiful Soup. You might, for example, search for a tag that doesn't exist in the document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footer_tag = cheese_doc.find(\"footer\")\n",
    "\n",
    "footer_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup doesn't return an error if it can't find the tag you want. Instead, it returns a `NoneType`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(footer_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you try to call a method on the object that Beautiful Soup returned anyway, you might end up with an error like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footer_tag.find(\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might also inadvertently try to get an attribute of a tag that wasn't actually found. You'll get a similar error in that case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footer_tag['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever you see something like `TypeError: 'NoneType' object is not subscriptable`, it's a good idea to check to see whether your method calls are indeed finding the thing you were looking for.\n",
    "\n",
    "Making things slightly more complicated, the `.find_all()` method will return an empty list if it doesn't find any of the tags you wanted, which can also make you unaware that you didn't find what you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footer_tags = cheese_doc.find_all(\"footer\")\n",
    "print(footer_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you attempt to access one of the elements of this regardless, you get... an `IndexError`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(footer_tags[0].string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I've mentioned before, all of these errors are helpful pointers to where you might have gone wrong. In general, try to learn about the various types of errors you might encounter since they'll help you debug your code faster.\n",
    "\n",
    "## And some further reading\n",
    "\n",
    "* [Chapter 11](https://automatetheboringstuff.com/chapter11/) from Al Sweigart's [Automate the Boring Stuff with Python](https://automatetheboringstuff.com/) is another good take on this material (and discusses a wider range of techniques).\n",
    "* [The official Beautiful Soup documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) provides a systematic walkthrough of the library's functionality. If you find yourself thinking, \"it really should be easy to do the thing that I want to do, why isn't it easier?\" then check the documentation! Leonard's probably already thought of a way to make it easier and implemented a feature in the code to help you out.\n",
    "* Beautiful Soup is the best scraping library out there for quick jobs, but if you have a larger site that you need to scrape, you might look into [Scrapy](http://scrapy.org/), which bundles a good parser with a framework for writing web \"spiders\" (i.e., programs that parse web pages and follow the links found there, in order to make a catalog of an entire web site, not just a single web page)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
