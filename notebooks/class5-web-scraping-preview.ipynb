{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with Beautiful Soup\n",
    "\n",
    "Version 1 of thits notebook was written in 2019, based on lessons by [Alison Parrish](http://www.decontextualize.com/) and [Jinho Choi](https://github.com/emory-courses/data-science/blob/master/course/data_aggregation/data_aggregation.ipynb). This version has been revised to incorporate additional materials from [Dan Sinykin](http://www.dansinykin.com/) and [Melanie Walsh](https://melaniewalsh.org/intro-ca-jupyter-book/). \n",
    "\n",
    "\n",
    "## Why Do We Need To Scrape At All?\n",
    "\n",
    "To perform practical approaches to data science with text, we need...**text**. Some text is prepared for computational analysis and publicly available in digital libraries. We can easily get novels in the public domain as .txt files, for example, from [Project Gutenberg](https://www.gutenberg.org/). Or we can work with text from HathiTrust's vast collections through the [HathiTrust Research Center](https://analytics.hathitrust.org/). \n",
    "\n",
    "If we want to work with text from popular culture and the internet--and we do!--we often need to scrape the web. And in order to scrape the web, we need to learn a little bit about HTML. So that's where we'll be starting today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting HTML's anatomy with Developer Tools\n",
    "\n",
    "Thanks to Alison Parrish, we have a very simple example of HTML to begin with. It is about kittens. [Here's the rendered version](http://static.decontextualize.com/kittens.html), and [here's the HTML source code](https://raw.githubusercontent.com/ledeprogram/courses/master/databases/data/kittens.html).\n",
    "\n",
    "First we're going to use Developer Tools in Chrome to take a look at how `kittens.html` is organized. Click on the \"rendered version\" link above. In Chrome, ctrl-click (or right click) anywhere on the page and select \"Inspect Element.\" This will open Chrome's Developer Tools. Your screen should look (something) like this:\n",
    "\n",
    "<a href=\"http://static.decontextualize.com/snaps/kittens-dev-tools.png\"><img src=\"http://static.decontextualize.com/snaps/kittens-dev-tools.png\" alt=\"kittens-dev-tools\"/></a>\n",
    "\n",
    "In the upper panel, you see the web page you're inspecting. In the lower panel, you see a version of the HTML source code, with little arrows next to some of the lines. (The little arrows allow you to collapse parts of the HTML source that are hierarchically related.) As you move your mouse over the elements in the top panel, different parts of the source code will be highlighted. Chrome is showing you which parts of the source code are causing which parts of the page to show up. Pretty nice!\n",
    "\n",
    "Also note that this relationship works in reverse: you can move your mouse over some part of the source code in the lower panel, which will highlight in the top panel what that source code corresponds to on the page. We'll be using this later to visually identify the parts of the page that are interesting to us, so we can write code that extracts the contents of those parts automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characterizing the structure of kittens\n",
    "\n",
    "Let's go a little deeper down the HTML wormhole and take a look at the source code of kittens.html.\n",
    "\n",
    "It looks like:\n",
    "\n",
    "\t<!doctype html>\n",
    "\t<html>\n",
    "\t  <head>\n",
    "\t    <title>Kittens!</title>\n",
    "\t  </head>\n",
    "\t  <body>\n",
    "\t    <h1>Kittens and the TV Shows They Love</h1>\n",
    "\t    <div class=\"kitten\">\n",
    "\t      <h2>Fluffy</h2>\n",
    "\t      <div><img src=\"http://placekitten.com/100/100\"></div>\n",
    "\t      <ul class=\"tvshows\">\n",
    "\t        <li><a href=\"http://www.imdb.com/title/tt0106145/\">Deep Space Nine</a></li>\n",
    "\t        <li><a href=\"http://www.imdb.com/title/tt0088576/\">Mr. Belvedere</a></li>\n",
    "\t      </ul>\n",
    "\t      Last check-up: <span class=\"lastcheckup\">2014-01-17</span>\n",
    "\t    </div>\n",
    "\t    <div class=\"kitten\">\n",
    "\t      <h2>Monsieur Whiskeurs</h2>\n",
    "\t      <div><img src=\"http://placekitten.com/150/100\"></div>\n",
    "\t      <ul class=\"tvshows\">\n",
    "\t        <li><a href=\"http://www.imdb.com/title/tt0106179/\">The X-Files</a></li>\n",
    "\t        <li><a href=\"http://www.imdb.com/title/tt0098800/\">Fresh Prince</a></li>\n",
    "\t      </ul>\n",
    "\t      Last check-up: <span class=\"lastcheckup\">2013-11-02</span>\n",
    "\t    </div>\n",
    "\t  </body>\n",
    "\t</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty well organized HTML, but if you don't know how to read HTML, it will still look like a big jumble. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **EXERCISE:** Some HTML questions:\n",
    ">\n",
    "> * What's the parent tag of `<a href=\"http://www.imdb.com/title/tt0088576/\">Mr. Belvedere</a>`? \n",
    "> * Both `<div class=\"kitten\">` tags share a parent tag---what is it? What attributes are present on both `<img>` tags?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping kittens with Beautiful Soup\n",
    "\n",
    "We've examined `kittens.html` a bit now. What we'd like to do is write some code that is going to extract information from the HTML, like \"what is the last checkup date for each of these kittens?\" or \"what are Monsieur Whiskeur's favorite TV shows?\" To do so, we need to *parse* the HTML, and create a representation of it in our program that we can manipulate with Python.\n",
    "\n",
    "As mentioned earlier, HTML is hard to parse by hand. (Don't even try it. In particular, [don't parse HTML with regular expressions](http://stackoverflow.com/a/1732454).)\n",
    "\n",
    "[Beautiful Soup](http://www.crummy.com/software/BeautifulSoup/) is a Python library that parses HTML (even if it's poorly formatted) and allows us to extract and manipulate its contents. More specifically, it gives us some Python objects that we can call methods on to poke at the data contained therein. So instead of working with strings and bytes, we can work with Python objects, methods and data structures.\n",
    "\n",
    "Note that Beautiful Soup only *parses* HTML. It's still left to us to actually *get* the HTML from somewhere. In most cases, we'll want to download the HTML directly from the actual web. For that, we'll use the `get` method from the Python library `requests` ([link](https://2.python-requests.org/en/master/)).\n",
    "\n",
    "But first, let's import these two libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our libraries (which, if you're curious, I preinstalled for our class on JupyterHub)\n",
    "from bs4 import BeautifulSoup\n",
    "import requests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it worked, you won't get an error message. You will see that the execution counter has been incremented by 1.\n",
    "\n",
    "To begin, let's use the \"get\" method to make an http request (the eponymous \"requests\") to get the contents of kittens.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(\"http://static.decontextualize.com/kittens.html\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that \"resp\" is a Python object, and not plain text.\n",
    "\n",
    "Also note that the \"get\" method makes things easy by guessing at the document's character encoding, so you don't need to worry about it--at least for the moemnt. (We'll talk more about encoding next class)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a string with the contents of the web page in text format we use the \"text\" method for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_str = resp.text\n",
    "html_str # a nice shortcut: if you finish a cell with a variable, Jupyter will just display that variable \n",
    "         # you don't need a print statement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks like a mess but it's apparent that we've obtained the data as desired.\n",
    "\n",
    "Now we need to create a BeautifulSoup object from that data. \n",
    "\n",
    "To make a BeautifulSoup document, we call `BeautifulSoup()` with two parameters: the `html_str` from our HTTP request and [the kind of parser](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#specifying-the-parser-to-use) that we want to use, which will always be `\"html.parser\"` for our purposes.\n",
    "\n",
    "It looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = BeautifulSoup(html_str, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's see what we've got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And voila! \n",
    "\n",
    "This object, which I've I've assigned to the variable `document`, supports a number of interesting methods that allow us to dig into the contents of the HTML. \n",
    "\n",
    "Primarily what we'll be working with are `Tag` objects and `ResultSet` objects, which are essentially just lists of `Tag` objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding a tag\n",
    "\n",
    "As we've previously discussed, HTML documents are composed of tags. To represent this, Beautiful Soup has a type of value that represents tags. We can use the `.find()` method of the `BeautifulSoup` object to find a tag that matches a particular tag name. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_tag = document.find('h1')\n",
    "\n",
    "h1_tag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Tag` object has several interesting attributes and methods. The `string` attribute of a `Tag` object, for example, returns a string representing that tag's contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_tag.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **EXERCISE:** How would you find an HTML element that contains an image? (Hint: the HTML image tag is \"img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two things you might have noticed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thing 1:** You may have tried to view the text associated with the image--or maybe you didn't--but in any case, it doesn't work. This is because the location of the image is considered an *attribute* of the `<img>` tag, rather than simply being enclosed within it. \n",
    "\n",
    "Thankfully, BeautifulSoup makes it (relatively) easy to access the attributes of a tag by treating it as a dictionary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE FOR FOLKS USING PYTHON FOR THE FIRST TIME IN THIS COURSE:**\n",
    "\n",
    "Unlike R, which (I think) just has lists, Python has two data types that store values: lists which are ordered, and store only one value, and dictionaries-- what I'm talking about here-- that store UNORDERED sets of values in key:value pairs. \n",
    "\n",
    "So, to print out the `src` attribute of the first `<img>` tag in the document, you would write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img['src']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More generally, dictionaries use this square-bracket index style of syntax, with the name of the attribute whose value you want typed as a string inside the brackets. \n",
    "\n",
    "For more on dictionaries, see [this notebook](dictionaries-sets-tuples.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thing 2:** A second thing you might have noticed that there is more than one `<img>` tag in `kittens.html`! If more than one tag matches the name you pass to `.find()`, it returns only the *first* matching tag. (A better name for `.find()` might be `find_first`.) Which leads us to..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding multiple tags\n",
    "\n",
    "It's very often the case that we want to find not just one tag that matches particular criteria, but ALL tags matching those criteria. For that, we use the `.find_all()` method of the `BeautifulSoup` object. For example, to find all `h2` tags in the document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_tags = document.find_all('h2')\n",
    "\n",
    "h2_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we want to see just the text of these headers?\n",
    "\n",
    "To do so, we're going to need to use a loop.\n",
    "\n",
    "We're going to use some 'for' loop syntax that's very common in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in h2_tags:\n",
    "    print(tag.string) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This conventiently gives you a variable, `tag`, that updates with the appropriate value each time you iterate. \n",
    "\n",
    "(For more on loops and counting, see [this notebook](counting.ipynb)). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for specific attributes\n",
    "\n",
    "Both the `.find()` and `.find_all()` methods can search not just for tags with particular names, but also for tags that have particular attributes. For that, we use the `attrs` keyword argument, giving it a dictionary that associates attribute names as keys and the desired attribute value as values. For example, to find all `span` tags with a `class` attribute of `lastcheckup`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkup_tags = document.find_all('span', attrs={'class': 'lastcheckup'})\n",
    "\n",
    "checkup_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **EXERCISE**: Can you create a list of the dates of each of the checkups using a 'for' loop and the `.string` method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List comprehension in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a confusing yet useful (and therefore ubituitous) syntax that we will see in our code as we proceed in this course. It is called list comprehension, and it's a way of doing the above in a single line. It looks something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkup_dates = [tag.string for tag in checkup_tags]\n",
    "\n",
    "checkup_dates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More generally, *list comprehension* helps with a very common task in both data analysis and programming more generally: when you want to apply an operation to every item in a list (e.g., scaling the numbers in a list by a fixed factor), or creating a copy of a list with only those items that match a particular criterion (e.g., eliminating values that fall below a certain threshold). \n",
    "\n",
    "A list comprehension has a few parts, arranged like so:\n",
    "\n",
    "> `[` *predicate expression* `for` *temporary variable name* `in` *source list* `if` *membership expression* `]`\n",
    "\n",
    "Working through these parts one by one, they are: \n",
    "\n",
    "* a source list, or the list whose values will be transformed or filtered;\n",
    "* a predicate expression, to be evaluated for every item in the list;\n",
    "* (optionally) a membership expression that determines whether or not an item in the source list will be included in the result of evaluating the list comprehension, based on whether the expression evaluates to True or False; and\n",
    "* a temporary variable name by which each value from the source list will be known in the predicate expression and membership expression.\n",
    "\n",
    "The words for, in, and if are a part of the syntax of the expression. They don't mean anything in particular (and in fact, they do completely different things in other parts of the Python language). You just have to spell them right and put them in the right place in order for the list comprehension to work.\n",
    "\n",
    "You can see more examples of this in action [here](lists.ipynb).\n",
    "\n",
    "It's also OK if you never use list comprehension in your code. But it will show up in the future so I want you to be able to recognize it when you see it and remember this explanation (or google it if you forget). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding tags within tags\n",
    "\n",
    "Beautiful Soup's `.find()` and `.find_all()` methods are actually more powerful than I've let on thus far. [Check out the details in the official Beautiful Soup documentation](http://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-all) to learn about all that BeautifulSoup can do. \n",
    "\n",
    "But for now, let's give ourselves a challenge: \n",
    "\n",
    "Let's say that we wanted to print out a list of the name of each kitten, along with a list of the names of that kitten's favorite TV shows. In other words, we want to print out something that looks like this:\n",
    "\n",
    "    Fluffy: Deep Space Nine, Mr. Belvedere\n",
    "    Monsieur Whiskeurs: The X-Files, Fresh Prince\n",
    "    \n",
    "In order to do this, we need to find *not just* tags with particular names, but tags with *particular hierarchical relationships* with other tags. I.e., we need to identify all of the kittens, and then find the shows that belong to that kitten. This kind of search is made easy by the fact that you can use `.find()` and `.find_all()` methods not just on the entire document, but on *individual tags*. When you use these methods on tags, they search for matching tags that are specifically *children of* the tag that you call them on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's refer back to the HTML of our kittens doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can see that information about individual kittens is grouped together under `<div>` tags with a `class` attribute of `kitten`. \n",
    "\n",
    "To find a list of all `<div>` tags with `class` set to `kitten`, what might we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitten_tags = # complete w/ code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we're not done yet! We still need to loop over that list of tags and find both the names and the shows associated with each kitten, Let's start with the first one of those-- the names: \n",
    "\n",
    "To loop through the list of kitten tags to find each of their names, how might we do that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kitten_tag in kitten_tags:\n",
    "    # rest of loop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll go one more step. Looping over all of the kitten tags, we'll find not just the `<h2>` tag with the kitten's name, but *all* `<a>` tags (which contain the names of the TV shows that we were looking for). How might we do that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kitten_tag in kitten_tags:\n",
    "    h2_tag = kitten_tag.find('h2')\n",
    "    print(h2_tag.string)\n",
    "    # new stuff here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **THE CHALLENGE:** Using your newfound string manipulation skills from last night's homework, can you modify this list so that the names and shows are printed out in the following format:\n",
    ">\n",
    "\n",
    "    Fluffy: Deep Space Nine, Mr. Belvedere\n",
    "    Monsieur Whiskeurs: The X-Files, Fresh Prince\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kitten_tag in kitten_tags:\n",
    "    h2_tag = kitten_tag.find('h2')\n",
    "    a_tags = kitten_tag.find_all('a')\n",
    "    \n",
    "    # lots of ways to do this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A final helpful method for finding sibling tags\n",
    "\n",
    "Often, the tags we're looking for don't have a distinguishing characteristic, like a `class` attribute, that allows us to find them using `.find()` and `.find_all()`, and the tags also aren't in a parent-child relationship. This can be tricky! Take the following HTML snippet, for example:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cheese_html = \"\"\"\n",
    "<h2>Camembert</h2>\n",
    "<p>A soft cheese made in the Camembert region of France.</p>\n",
    "\n",
    "<h2>Cheddar</h2>\n",
    "<p>A yellow cheese made in the Cheddar region of... France, probably, idk whatevs.</p>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our task was to create a list of the name of the cheese followed by the description that follows in the `<p>` tag directly afterward, we'd be out of luck. Fortunately, Beautiful Soup has a `.find_next_sibling()` method, which allows us to search for the next tag that is a *sibling* of the tag you're calling it on (i.e., the two tags share a parent), that also matches particular criteria. So, for example, to accomplish the task outlined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = BeautifulSoup(cheese_html, \"html.parser\")\n",
    "cheese_dict = {}\n",
    "for h2_tag in document.find_all('h2'):\n",
    "    cheese_name = h2_tag.string\n",
    "    cheese_desc_tag = h2_tag.find_next_sibling('p')\n",
    "    cheese_dict[cheese_name] = cheese_desc_tag.string\n",
    "\n",
    "cheese_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now know most of what you need to know to scrape web pages effectively. Good job!\n",
    "\n",
    "But before you're done, we should talk about what to do when things go wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When things go wrong with Beautiful Soup\n",
    "\n",
    "A number of things might go wrong with Beautiful Soup. You might, for example, search for a tag that doesn't exist in the document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footer_tag = document.find(\"footer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup doesn't return an error if it can't find the tag you want. Instead, it returns `None`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(footer_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you try to call a method on the object that Beautiful Soup returned anyway, you might end up with an error like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footer_tag.find(\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might also inadvertently try to get an attribute of a tag that wasn't actually found. You'll get a similar error in that case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footer_tag['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever you see something like `TypeError: 'NoneType' object is not subscriptable`, it's a good idea to check to see whether your method calls are indeed finding the thing you were looking for.\n",
    "\n",
    "However, the `.find_all()` method will return an empty list if it doesn't find any of the tags you wanted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footer_tags = document.find_all(\"footer\")\n",
    "print(footer_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you attempt to access one of the elements of this regardless..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(footer_tags[0].string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...you'll get an `IndexError`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "* [Chapter 11](https://automatetheboringstuff.com/chapter11/) from Al Sweigart's [Automate the Boring Stuff with Python](https://automatetheboringstuff.com/) is another good take on this material (and discusses a wider range of techniques).\n",
    "* [The official Beautiful Soup documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) provides a systematic walkthrough of the library's functionality. If you find yourself thinking, \"it really should be easy to do the thing that I want to do, why isn't it easier?\" then check the documentation! Leonard's probably already thought of a way to make it easier and implemented a feature in the code to help you out.\n",
    "* Beautiful Soup is the best scraping library out there for quick jobs, but if you have a larger site that you need to scrape, you might look into [Scrapy](http://scrapy.org/), which bundles a good parser with a framework for writing web \"spiders\" (i.e., programs that parse web pages and follow the links found there, in order to make a catalog of an entire web site, not just a single web page)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
